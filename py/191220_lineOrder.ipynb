{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify Out of Order Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from scipy.optimize import least_squares\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "\n",
    "from waveCal import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LFC\n",
    "lfc_files = glob('/mnt/home/lzhao/ceph/lfc5*/LFC_*.fits')\n",
    "ckpt_files = glob('/mnt/home/lzhao/ceph/ckpt5*/LFC_19*.npy')\n",
    "lfc_files, lfc_times = sortFiles(lfc_files, get_mjd=True)\n",
    "ckpt_files = sortFiles(ckpt_files)\n",
    "num_lfc_files = len(lfc_files)\n",
    "\n",
    "hdus = fits.open(lfc_files[0])\n",
    "t_spec = hdus[1].data['spectrum'].copy()\n",
    "t_errs = hdus[1].data['uncertainty'].copy()\n",
    "t_mask = hdus[1].data['pixel_mask'].copy()\n",
    "hdus.close()\n",
    "nord, npix = t_spec.shape\n",
    "\n",
    "lfc_orders = range(45,76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ThAr\n",
    "thar_files = glob('/mnt/home/lzhao/ceph/thar5*/ThAr_*.fits')\n",
    "thid_files  = glob('/mnt/home/lzhao/ceph/thid5*/ThAr_*.thid')\n",
    "thar_files, thar_times = sortFiles(thar_files, get_mjd=True)\n",
    "thar_files = thar_files[1:] # First file is from before LFCs\n",
    "thar_times = thar_times[1:]\n",
    "thid_files = sortFiles(thid_files) [1:]\n",
    "num_thar_files = len(thar_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildLineList(file_list,file_times,\n",
    "                  order_range=range(45,76),\n",
    "                  line_cutoff=0.5, file_cutoff=0.5,verbose=False):\n",
    "    ### Gather calibration information\n",
    "    # Find all observed lines in each order and their wavlengths\n",
    "    if verbose:\n",
    "        print('Finding all observed modes')\n",
    "    orders, names, waves = buildLineDB(file_list, order_list=order_range)\n",
    "\n",
    "    # Find x-values of observed lines\n",
    "    if verbose:\n",
    "        print('Finding line center for each mode')\n",
    "    x_values = getLineMeasures(file_list, orders, names)\n",
    "    \n",
    "    \n",
    "    ### Vetting\n",
    "    # Find where there is no line information\n",
    "    x_values[x_values < 1] = np.nan # This will throw a warning\n",
    "    \n",
    "    # Get rid of bad lines\n",
    "    good_lines = np.mean(np.isnan(x_values),axis=0) < line_cutoff\n",
    "    # Trim everything\n",
    "    names  = names[good_lines]\n",
    "    orders = orders[good_lines]\n",
    "    waves  = waves[good_lines]\n",
    "    x_values = x_values[:,good_lines]\n",
    "    if verbose:\n",
    "        num_good = np.sum(good_lines)\n",
    "        num_total = good_lines.size\n",
    "        print('{} of {} lines cut ({:.3}%)'.format(\n",
    "            (num_total - num_good),num_total,\n",
    "            (num_total - num_good)/num_total*100))\n",
    "    \n",
    "    # Get rid of bad files\n",
    "    good_files = np.mean(np.isnan(x_values),axis=1) < file_cutoff\n",
    "    # Trim everything\n",
    "    x_values = x_values[good_files]\n",
    "    exp_list = file_list[good_files]\n",
    "    file_times = file_times[good_files]\n",
    "    if verbose:\n",
    "        num_good = np.sum(good_files)\n",
    "        num_total = good_files.size\n",
    "        print('{} of {} files cut ({:.3}%)'.format(\n",
    "            (num_total - num_good),num_total,\n",
    "            (num_total - num_good)/num_total*100))\n",
    "        print('Files that were cut:')\n",
    "        print(file_list[~good_files])\n",
    "    \n",
    "    line_dict = {}\n",
    "    line_dict['names'] = names\n",
    "    line_dict['orders'] = orders\n",
    "    line_dict['waves'] = waves\n",
    "    line_dict['x_values'] = x_values\n",
    "    line_dict['times'] = file_times\n",
    "    line_dict['files'] = exp_list\n",
    "    line_dict['bad_pix'] = np.isnan(x_values)\n",
    "    return line_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfc_lines = buildLineList(ckpt_files, lfc_times, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thar_lines = buildLineList(thid_files, thar_times, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Order of Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfc_left = np.zeros_like(lfc_lines['x_values'],dtype=bool)\n",
    "lfc_right = np.zeros_like(lfc_lines['x_values'],dtype=bool)\n",
    "for m in np.unique(lfc_lines['orders']):\n",
    "    ord_mask = lfc_lines['orders']==m\n",
    "    wave_sort = np.argsort(lfc_lines['waves'][ord_mask])\n",
    "    for i,exp in enumerate(lfc_lines['x_values']):\n",
    "        exp_sort = exp[ord_mask][wave_sort]\n",
    "        exp_diff = np.diff(exp_sort)\n",
    "        lfc_left[i,ord_mask] = np.insert(np.logical_or(exp_diff>0,np.isnan(exp_diff)),0,False)\n",
    "        lfc_right[i,ord_mask] = np.append(np.logical_or(exp_diff>0,np.isnan(exp_diff)),False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thar_left = np.zeros_like(thar_lines['x_values'],dtype=bool)\n",
    "thar_right = np.zeros_like(thar_lines['x_values'],dtype=bool)\n",
    "for m in np.unique(thar_lines['orders']):\n",
    "    ord_mask = thar_lines['orders']==m\n",
    "    wave_sort = np.argsort(thar_lines['waves'][ord_mask])\n",
    "    for i,exp in enumerate(thar_lines['x_values']):\n",
    "        exp_sort = exp[ord_mask][wave_sort]\n",
    "        exp_diff = np.diff(exp_sort)\n",
    "        thar_left[i,ord_mask] = np.insert(np.logical_or(exp_diff>0,np.isnan(exp_diff)),0,False)\n",
    "        thar_right[i,ord_mask] = np.append(np.logical_or(exp_diff>0,np.isnan(exp_diff)),False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6.4*2,4.8))\n",
    "plt.title('Good LFC Lines')\n",
    "plt.xlabel('Line Number')\n",
    "plt.ylabel('Percentage of Good Lines')\n",
    "\n",
    "# Draw order boundaries\n",
    "old = 0\n",
    "for i,o in enumerate(lfc_lines['orders']):\n",
    "    if o!=old:\n",
    "        plt.axvline(i,color='0.75')\n",
    "        old=o\n",
    "plt.axvline(i+1,color='0.75')\n",
    "\n",
    "nan_lines = np.sum(np.isnan(lfc_lines['x_values']),axis=0)\n",
    "\n",
    "plt.plot((np.sum(np.logical_and(lfc_left,lfc_right),axis=0))/num_lfc_files,\n",
    "         'ko',label='both')\n",
    "plt.plot((np.sum(lfc_left,axis=0))/num_lfc_files,'c.',label='left')\n",
    "plt.plot((np.sum(lfc_right,axis=0))/num_lfc_files,'r.',label='right')\n",
    "plt.legend(loc=3)\n",
    "plt.savefig('./Figures/191220_lfcOrder.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6.4*2,4.8))\n",
    "plt.title('Good ThAr Lines')\n",
    "plt.xlabel('Line Number')\n",
    "plt.ylabel('Percentage of Good Lines')\n",
    "\n",
    "# Draw order boundaries\n",
    "old = 0\n",
    "for i,o in enumerate(thar_lines['orders']):\n",
    "    if o!=old:\n",
    "        plt.axvline(i,color='0.75')\n",
    "        old=o\n",
    "plt.axvline(i+1,color='0.75')\n",
    "\n",
    "plt.plot((np.sum(np.logical_and(thar_left,thar_right),axis=0))/num_thar_files,\n",
    "         'ko',label='both')\n",
    "plt.plot((np.sum(thar_left,axis=0))/num_thar_files,'c.',label='left')\n",
    "plt.plot((np.sum(thar_right,axis=0))/num_thar_files,'r.',label='right')\n",
    "plt.legend(loc=3)\n",
    "plt.savefig('./Figures/191220_tharOrder.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
