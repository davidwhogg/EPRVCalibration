{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify LFCS Giving Outrageous Eigen Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits\n",
    "from astropy.time import Time\n",
    "from scipy import interpolate\n",
    "from scipy.optimize import minimize, least_squares, curve_fit\n",
    "from mpfit import mpfit\n",
    "\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather files\n",
    "lfc_files = glob('/mnt/home/lzhao/ceph/lfc5a/LFC_*.fits')\n",
    "num_files = len(lfc_files)\n",
    "print(f'Number of files: {num_files}')\n",
    "\n",
    "# Set some useful, general values\n",
    "hdus = fits.open(lfc_files[0])\n",
    "t_spec = hdus[1].data['spectrum'].copy()\n",
    "t_errs = hdus[1].data['uncertainty'].copy()\n",
    "t_mask = hdus[1].data['pixel_mask'].copy()\n",
    "hdus.close()\n",
    "nord, npix = t_spec.shape\n",
    "\n",
    "lfc_orders = range(41,76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at all the LFCs we've gathered\n",
    "plt.figure(figsize=(6.4*2,4.8))\n",
    "plt.title('Epoch 5 LFC Spectra: Order 60')\n",
    "plt.xlabel('Pixel')\n",
    "plt.ylabel('Extracted Value + \"Time\" Offset')\n",
    "colors = sns.color_palette('plasma',95)\n",
    "for file_name in tqdm(lfc_files):\n",
    "    hdus=fits.open(file_name)\n",
    "    mjd = Time(hdus[0].header['MIDPOINT'],format='isot').mjd\n",
    "    plt.plot(range(3000,3050),hdus[1].data['spectrum'][60][3000:3050]+(int(mjd)-58696)/10.,\n",
    "             color=colors[int(mjd)-58696],alpha=0.1)\n",
    "    hdus.close()\n",
    "plt.xlim(3000,3050)\n",
    "plt.ylim(0,10)\n",
    "plt.axhline((int(Time('2019-09-22',format='isot').mjd)-58696)/10,color='g')\n",
    "plt.axhline((int(Time('2019-10-06',format='isot').mjd)-58696)/10,color='g')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./Figures/191113_lfcShifts.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify unique nights of LFC data\n",
    "lfc_dates = np.empty_like(lfc_files)\n",
    "for i in range(len(lfc_files)):\n",
    "    lfc_dates[i] = os.path.basename(lfc_files[i]).split('_')[-1].split('.')[0]\n",
    "np.unique(lfc_dates[np.argsort(lfc_dates.astype(int))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Find Those Bad Exposures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from waveCal import *\n",
    "ckpt_files  = glob('/mnt/home/lzhao/ceph/ckpt5a/LFC_19*.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort files by date:\n",
    "file_times = np.empty_like(ckpt_files,dtype='float')\n",
    "for i in range(len(ckpt_files)):\n",
    "    file_times[i] = os.path.basename(ckpt_files[i]).split('_')[-1][:-4]\n",
    "ckpt_files = np.array(ckpt_files)[np.argsort(file_times)]\n",
    "\n",
    "file_times = np.empty_like(lfc_files,dtype='float')\n",
    "for i in range(len(lfc_files)):\n",
    "    file_times[i] = os.path.basename(lfc_files[i]).split('_')[-1][:-5]\n",
    "lfc_files = np.array(lfc_files)[np.argsort(file_times)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data, construct wavelength solution, make pretty for PCA\n",
    "def pcaSetup(file_list, x_range=(500,7000), m_range=(45,75),\n",
    "             allow_file_error=True, vet_pxls=True, vet_exps=True):\n",
    "    # Construct wavelength \"grids\"\n",
    "    x_range = np.arange(*x_range).astype(float)\n",
    "    m_range = np.arange(*m_range).astype(float)\n",
    "    x_grid, m_grid = np.meshgrid(x_range,m_range)\n",
    "    x_grid = x_grid.flatten()\n",
    "    m_grid = m_grid.flatten()\n",
    "    \n",
    "    # Load in all wavelength solutions\n",
    "    w_fit_array = np.empty((len(file_list),len(x_grid)))\n",
    "    if file_list[0].split('.')[-1] == 'thid':\n",
    "        def readFunc(file_name):\n",
    "            x,m,w = readThid(file_name)\n",
    "            e = None\n",
    "            return x,m,e,w\n",
    "    else:\n",
    "        def readFunc(file_name):\n",
    "             return readParams(file_name)\n",
    "    \n",
    "    print('Reading in files')\n",
    "    used_files = []\n",
    "    for i in tqdm(range(len(file_list))):\n",
    "        file_name = file_list[i]\n",
    "        try:\n",
    "            x,m,e,w = readFunc(file_name)\n",
    "            w_fit_array[i] = interp_train_and_predict(x_grid,m_grid,x,m,w,e)\n",
    "            used_files.append(os.path.basename(file_name))\n",
    "        except ValueError as err:\n",
    "            if not allow_file_error:\n",
    "                raise err\n",
    "            w_fit_array[i,:] = np.nan\n",
    "    \n",
    "    # Bad lines/exposure\n",
    "    good = np.isfinite(w_fit_array)\n",
    "    bad  = np.logical_not(good)\n",
    "    if vet_exps:\n",
    "        exp_okay = np.sum(good, axis=1) > 3\n",
    "        w_fit_array = w_fit_array[exp_okay,:]\n",
    "        print(f\"Not okay Exposures: {np.sum(~exp_okay)}\")\n",
    "        print(np.array(file_list)[~exp_okay])\n",
    "        used_files = np.array(file_list)[exp_okay]\n",
    "    if vet_pxls:\n",
    "        pxl_okay = np.sum(good, axis=0) > 3\n",
    "        w_fit_array = w_fit_array[:,pxl_okay]\n",
    "        print(f\"Not okay Pixels: {np.sum(~pxl_okay)}\")\n",
    "        x_grid = x_grid[pxl_okay]\n",
    "        m_grid = m_grid[pxl_okay]\n",
    "    good = np.isfinite(w_fit_array)\n",
    "    bad = np.logical_not(good)\n",
    "    \n",
    "    # Find mean wavelength pixel by pixel\n",
    "    mean_w_fit = np.empty(w_fit_array.shape[1])\n",
    "    for i in range(w_fit_array.shape[1]):\n",
    "        mean_w_fit[i] = np.nanmean(w_fit_array[:,i])\n",
    "    \n",
    "    # Replace bad pixels with mean value\n",
    "    # THIS IS TERRIBLE\n",
    "    for i in range(w_fit_array.shape[0]):\n",
    "        w_fit_array[i][bad[i]] = mean_w_fit[bad[i]]\n",
    "    \n",
    "    return w_fit_array, mean_w_fit, used_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_fit_array, mean_w_fit, used_files = pcaSetup(ckpt_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find eigenvectors\n",
    "svd = TruncatedSVD(n_components=5,n_iter=7,random_state=42)\n",
    "uu = svd.fit_transform(w_fit_array - mean_w_fit[None, :])\n",
    "ss = svd.singular_values_\n",
    "vv = svd.components_\n",
    "ec = (uu.dot(np.diag(ss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify 3 sigma outliers\n",
    "mask = np.zeros_like(ec.shape[1],dtype=bool)\n",
    "for i in range(3):\n",
    "    plt.plot(ec[:,i])\n",
    "    mask = np.logical_or(mask,abs(ec[:,i]) > (3*np.std(ec[:,i])))\n",
    "    plt.plot(np.arange(len(ec[:,i]))[mask],ec[mask,i],'r.')\n",
    "    #print(used_files[mask])\n",
    "#plt.ylim(-500,500)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./Figures/191113_outliers1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which were the bad files?\n",
    "used_files[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do the eigenvectors look?\n",
    "# Identify areas giving trouble\n",
    "x_range = np.arange(500,7000).astype(float)\n",
    "m_range = np.arange(45,75).astype(float)\n",
    "x_grid, m_grid = np.meshgrid(x_range,m_range)\n",
    "x_grid = x_grid.flatten()\n",
    "m_grid = m_grid.flatten()\n",
    "for k in range(3):\n",
    "    plt.figure()\n",
    "    plt.scatter(x_grid, m_grid, c=vv[k])\n",
    "    plt.title(\"eigenvector {:d}\".format(k))\n",
    "    plt.colorbar()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./Figures/191113_eigenvector{k}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot troublesome areas and identify differences in outlier spectra\n",
    "plt.figure(figsize=(6.4*3,4.8*5))\n",
    "ax1 = plt.subplot(511)\n",
    "ax1.set_title('Order 45')\n",
    "ax2 = plt.subplot(512)\n",
    "ax2.set_title('Order 46')\n",
    "ax3 = plt.subplot(513)\n",
    "ax3.set_title('Order 47')\n",
    "ax4 = plt.subplot(514)\n",
    "ax4.set_title('Order 48')\n",
    "ax5 = plt.subplot(515)\n",
    "ax5.set_title('Order 49')\n",
    "colors = sns.color_palette('plasma',1150-1062)\n",
    "for file_name in tqdm(lfc_files):\n",
    "    date,obsn,_ = os.path.basename(file_name).split('_')[-1].split('.')\n",
    "    if date != '190818':\n",
    "        continue\n",
    "    \n",
    "    hdus = fits.open(file_name)\n",
    "    spec = hdus[1].data['spectrum'].copy()\n",
    "    hdus.close()\n",
    "    \n",
    "    ax1.plot(range(500,1000),spec[45,500:1000],color=colors[int(obsn)-1062],alpha=0.1)\n",
    "    ax2.plot(range(6500,7000),spec[46,6500:7000],color=colors[int(obsn)-1062],alpha=0.1)\n",
    "    ax3.plot(range(6500,7000),spec[47,6500:7000],color=colors[int(obsn)-1062],alpha=0.1)\n",
    "    ax4.plot(range(500,1000),spec[48,500:1000],color=colors[int(obsn)-1062],alpha=0.1)\n",
    "    ax5.plot(range(500,1000),spec[49,500:1000],color=colors[int(obsn)-1062],alpha=0.1)\n",
    "\n",
    "for file_name in used_files[mask]:\n",
    "    hdus = fits.open('/mnt/home/lzhao/ceph/lfc5a/'+os.path.basename(file_name)[:-4]+'.fits')\n",
    "    spec = hdus[1].data['spectrum'].copy()\n",
    "    hdus.close()\n",
    "    \n",
    "    ax1.plot(range(500,1000),spec[45,500:1000],color='k')\n",
    "    ax2.plot(range(6500,7000),spec[46,6500:7000],color='k')\n",
    "    ax3.plot(range(6500,7000),spec[47,6500:7000],color='k')\n",
    "    ax4.plot(range(500,1000),spec[48,500:1000],color='k')\n",
    "    ax5.plot(range(500,1000),spec[49,500:1000],color='k')\n",
    "\n",
    "ax1.set_xlim(500,1000)\n",
    "ax2.set_xlim(6500,7000)\n",
    "ax3.set_xlim(6500,7000)\n",
    "ax4.set_xlim(500,1000)\n",
    "ax5.set_xlim(500,1000)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'./Figures/191113_problems1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a first round of outlier cuts, the clear issue is lower signal.  Let's now test for some cuts for signal and then iterate again without these outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot errors of the line fits (can we make a cut from that?)\n",
    "plt.figure(figsize=(6.4*3,4.8*5))\n",
    "ax1 = plt.subplot(511)\n",
    "ax1.set_title('Order 41')\n",
    "ax2 = plt.subplot(512)\n",
    "ax2.set_title('Order 42')\n",
    "ax3 = plt.subplot(513)\n",
    "ax3.set_title('Order 43')\n",
    "ax4 = plt.subplot(514)\n",
    "ax4.set_title('Order 44')\n",
    "ax5 = plt.subplot(515)\n",
    "ax5.set_title('Order 45')\n",
    "colors = sns.color_palette('plasma',1150-1062)\n",
    "num_lines = np.zeros_like(used_files,dtype=float)\n",
    "for i in tqdm(range(len(used_files))):\n",
    "    file_name = used_files[i]\n",
    "    x,m,e,w = readParams(file_name)\n",
    "    num_lines[i] = len(e)\n",
    "    \n",
    "    ax1.plot(x[m==41],e[m==41],alpha=0.1)\n",
    "    ax2.plot(x[m==42],e[m==42],alpha=0.1)\n",
    "    ax3.plot(x[m==43],e[m==43],alpha=0.1)\n",
    "    ax4.plot(x[m==44],e[m==44],alpha=0.1)\n",
    "    ax5.plot(x[m==45],e[m==45],alpha=0.1)\n",
    "\n",
    "for file_name in used_files[mask]:\n",
    "    x,m,e,w = readParams(file_name)\n",
    "    \n",
    "    ax1.plot(x[m==41],e[m==41],color='k')\n",
    "    ax2.plot(x[m==42],e[m==42],color='k')\n",
    "    ax3.plot(x[m==43],e[m==43],color='k')\n",
    "    ax4.plot(x[m==44],e[m==44],color='k')\n",
    "    ax5.plot(x[m==45],e[m==45],color='k')\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig(f'./Figures/191113_problems1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers just have less lines in general, let's cut for that\n",
    "num_lines = np.zeros_like(used_files,dtype=float)\n",
    "for i in tqdm(range(len(used_files))):\n",
    "    file_name = used_files[i]\n",
    "    x,m,e,w = readParams(file_name)\n",
    "    num_lines[i] = len(e)\n",
    "    \n",
    "for file_name in used_files[mask]:\n",
    "    x,m,e,w = readParams(file_name)\n",
    "    plt.axvline(len(e),color='r')\n",
    "plt.hist(num_lines,50);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteration Two\n",
    "Cut out exposures with less than 15,000 lines.  Fewer lines tends to correspond to exposures with lower signal and therefore either orders without any lines or teeny-tiny lines that are hard to find."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcaSetup(file_list, x_range=(500,7000), m_range=(45,75),\n",
    "             allow_file_error=True, vet_pxls=True, vet_exps=True,\n",
    "             verbose=False):\n",
    "    # Construct wavelength \"grids\"\n",
    "    x_range = np.arange(*x_range).astype(float)\n",
    "    m_range = np.arange(*m_range).astype(float)\n",
    "    x_grid, m_grid = np.meshgrid(x_range,m_range)\n",
    "    x_grid = x_grid.flatten()\n",
    "    m_grid = m_grid.flatten()\n",
    "    \n",
    "    # Load in all wavelength solutions\n",
    "    w_fit_array = np.empty((len(file_list),len(x_grid)))\n",
    "    if file_list[0].split('.')[-1] == 'thid':\n",
    "        line_requirement = 0\n",
    "        def readFunc(file_name):\n",
    "            x,m,w = readThid(file_name)\n",
    "            e = None\n",
    "            return x,m,e,w\n",
    "    else:\n",
    "        line_requirement = 15000\n",
    "        def readFunc(file_name):\n",
    "             return readParams(file_name)\n",
    "    \n",
    "    print('Reading in files')\n",
    "    used_files = []\n",
    "    for i in tqdm(range(len(file_list))):\n",
    "        file_name = file_list[i]\n",
    "        try:\n",
    "            x,m,e,w = readFunc(file_name)\n",
    "            if len(e) < line_requirement:\n",
    "                # THIS LIMIT IS HARD CODED\n",
    "                # WHICH IS DUMB\n",
    "                # SHOULD BE SOMETHING LIKE LINES PER ORDER\n",
    "                # ALSO ONLY WORKS ON LFCs\n",
    "                if verbose:\n",
    "                    print(f'File {file_name} has too few lines')\n",
    "                w_fit_array[i,:] = np.nan\n",
    "            else:\n",
    "                w_fit_array[i] = interp_train_and_predict(x_grid,m_grid,x,m,w,e)\n",
    "                used_files.append(os.path.basename(file_name))\n",
    "        except ValueError as err:\n",
    "            if not allow_file_error:\n",
    "                raise err\n",
    "            w_fit_array[i,:] = np.nan\n",
    "    \n",
    "    # Bad lines/exposure\n",
    "    good = np.isfinite(w_fit_array)\n",
    "    bad  = np.logical_not(good)\n",
    "    if vet_exps:\n",
    "        exp_okay = np.sum(good, axis=1) > 3\n",
    "        w_fit_array = w_fit_array[exp_okay,:]\n",
    "        if verbose:\n",
    "            print(f\"Not okay Exposures: {np.sum(~exp_okay)}\")\n",
    "            print(np.array(file_list)[~exp_okay])\n",
    "        used_files = np.array(file_list)[exp_okay]\n",
    "    if vet_pxls:\n",
    "        pxl_okay = np.sum(good, axis=0) > 3\n",
    "        w_fit_array = w_fit_array[:,pxl_okay]\n",
    "        if verbose:\n",
    "            print(f\"Not okay Pixels: {np.sum(~pxl_okay)}\")\n",
    "        x_grid = x_grid[pxl_okay]\n",
    "        m_grid = m_grid[pxl_okay]\n",
    "    good = np.isfinite(w_fit_array)\n",
    "    bad = np.logical_not(good)\n",
    "    \n",
    "    # Find mean wavelength pixel by pixel\n",
    "    mean_w_fit = np.empty(w_fit_array.shape[1])\n",
    "    for i in range(w_fit_array.shape[1]):\n",
    "        mean_w_fit[i] = np.nanmean(w_fit_array[:,i])\n",
    "    \n",
    "    # Replace bad pixels with mean value\n",
    "    # THIS IS TERRIBLE\n",
    "    for i in range(w_fit_array.shape[0]):\n",
    "        w_fit_array[i][bad[i]] = mean_w_fit[bad[i]]\n",
    "    \n",
    "    return w_fit_array, mean_w_fit, used_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_fit_array, mean_w_fit, used_files = pcaSetup(ckpt_files,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find eigenvectors\n",
    "svd = TruncatedSVD(n_components=5,n_iter=7,random_state=42)\n",
    "uu = svd.fit_transform(w_fit_array - mean_w_fit[None, :])\n",
    "ss = svd.singular_values_\n",
    "vv = svd.components_\n",
    "ec = (uu.dot(np.diag(ss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find time of each exposure\n",
    "time = np.zeros_like(used_files,dtype=float)\n",
    "for i in tqdm(range(len(used_files))):\n",
    "    file_name = used_files[i]\n",
    "    spec_name = '/mnt/home/lzhao/ceph/lfc5a/'+os.path.basename(file_name)[:-4]+'.fits'\n",
    "    hdus = fits.open(spec_name)\n",
    "    time[i] = Time(hdus[0].header['MIDPOINT'],format='isot').mjd\n",
    "    hdus.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6.4*3,4.8))\n",
    "ax1 = plt.gca()\n",
    "ax1.set_title('Coefficients Over Time')\n",
    "ax1.set_ylabel('Coefficient 0',color=sns.color_palette()[0])\n",
    "ax1.tick_params(axis='y', labelcolor=sns.color_palette()[0])\n",
    "ax1.plot(time,ec[:,0],'o-')\n",
    "mask = (abs(ec[:,0]) > (5e9))\n",
    "ax1.plot(np.arange(len(ec[:,0]))[mask],ec[mask,0],'o',color=sns.color_palette()[0],mec='r')\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "for i in range(1,5):\n",
    "    if i<3:\n",
    "        mask = np.logical_or(mask,(ec[:,i]-np.mean(ec[:,i])) > (3 * np.std(ec[:,i])))\n",
    "    ax2.plot(time,ec[:,i],'o-',color=sns.color_palette()[i])\n",
    "    #ax2.plot(np.arange(len(ec[:,i]))[mask],ec[mask,i],'o',mec='r')\n",
    "ax2.set_ylabel('All Other Coefficients')\n",
    "ax1.set_xlabel('Time [mjd]')\n",
    "for i in range((min(time.astype(int))),(max(time.astype(int)))+2):\n",
    "    plt.axvline(i,color='k',alpha=0.2)\n",
    "plt.tight_layout()\n",
    "plt.xlim(58709,58737)\n",
    "plt.savefig('./Figures/191113_ecVtime.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_files[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_range = np.arange(500,7000).astype(float)\n",
    "m_range = np.arange(45,75).astype(float)\n",
    "x_grid, m_grid = np.meshgrid(x_range,m_range)\n",
    "x_grid = x_grid.flatten()\n",
    "m_grid = m_grid.flatten()\n",
    "for k in range(5):\n",
    "    plt.figure()\n",
    "    plt.scatter(x_grid, m_grid, c=vv[k])\n",
    "    plt.title(\"eigenvector {:d}\".format(k))\n",
    "    plt.colorbar()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./Figures/191113_eigen2vector{k}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A quick check on other (sub-)epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt5b_files  = glob('/mnt/home/lzhao/ceph/ckpt5b/LFC_19*.npy')\n",
    "\n",
    "file_times = np.empty_like(ckpt5b_files,dtype='float')\n",
    "for i in range(len(ckpt5b_files)):\n",
    "    file_times[i] = os.path.basename(ckpt5b_files[i]).split('_')[-1][:-4]\n",
    "ckpt5b_files = np.array(ckpt5b_files)[np.argsort(file_times)]\n",
    "\n",
    "w_fit_array, mean_w_fit, used_files = pcaSetup(ckpt5b_files,verbose=True)\n",
    "# Find eigenvectors\n",
    "svd = TruncatedSVD(n_components=5,n_iter=7,random_state=42)\n",
    "uu = svd.fit_transform(w_fit_array - mean_w_fit[None, :])\n",
    "ss = svd.singular_values_\n",
    "vv = svd.components_\n",
    "ec = (uu.dot(np.diag(ss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "ax1.set_title('Coefficients Over Time')\n",
    "ax1.set_ylabel('Coefficient 0',color=sns.color_palette()[0])\n",
    "ax1.tick_params(axis='y', labelcolor=sns.color_palette()[0])\n",
    "ax1.plot(ec[:,0])\n",
    "mask = (abs(ec[:,0]) > (5e9))\n",
    "ax1.plot(np.arange(len(ec[:,0]))[mask],ec[mask,0],'o',color=sns.color_palette()[0],mec='r')\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "for i in range(1,5):\n",
    "    if i<3:\n",
    "        mask = np.logical_or(mask,(ec[:,i]-np.mean(ec[:,i])) > (3 * np.std(ec[:,i])))\n",
    "    ax2.plot(ec[:,i],color=sns.color_palette()[i])\n",
    "    ax2.plot(np.arange(len(ec[:,i]))[mask],ec[mask,i],'o',mec='r')\n",
    "ax2.set_ylabel('All Other Coefficients')\n",
    "ax1.set_xlabel('Exposure Number, but Kind of Time')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./Figures/191113_outliers5b.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_files[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_range = np.arange(500,7000).astype(float)\n",
    "m_range = np.arange(45,75).astype(float)\n",
    "x_grid, m_grid = np.meshgrid(x_range,m_range)\n",
    "x_grid = x_grid.flatten()\n",
    "m_grid = m_grid.flatten()\n",
    "for k in range(5):\n",
    "    plt.figure()\n",
    "    plt.scatter(x_grid, m_grid, c=vv[k])\n",
    "    plt.title(\"eigenvector {:d}\".format(k))\n",
    "    plt.colorbar()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./Figures/191113_eigen5bvector{k}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt5c_files  = glob('/mnt/home/lzhao/ceph/ckpt5c/LFC_19*.npy')\n",
    "\n",
    "file_times = np.empty_like(ckpt5c_files,dtype='float')\n",
    "for i in range(len(ckpt5c_files)):\n",
    "    file_times[i] = os.path.basename(ckpt5c_files[i]).split('_')[-1][:-4]\n",
    "ckpt5c_files = np.array(ckpt5c_files)[np.argsort(file_times)]\n",
    "\n",
    "w_fit_array, mean_w_fit, used_files = pcaSetup(ckpt5c_files,verbose=True)\n",
    "# Find eigenvectors\n",
    "svd = TruncatedSVD(n_components=5,n_iter=7,random_state=42)\n",
    "uu = svd.fit_transform(w_fit_array - mean_w_fit[None, :])\n",
    "ss = svd.singular_values_\n",
    "vv = svd.components_\n",
    "ec = (uu.dot(np.diag(ss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "ax1.set_title('Coefficients Over Time')\n",
    "ax1.set_ylabel('Coefficient 0',color=sns.color_palette()[0])\n",
    "ax1.tick_params(axis='y', labelcolor=sns.color_palette()[0])\n",
    "ax1.plot(ec[:,0])\n",
    "mask = (abs(ec[:,0]) > (5e9))\n",
    "ax1.plot(np.arange(len(ec[:,0]))[mask],ec[mask,0],'o',color=sns.color_palette()[0],mec='r')\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "for i in range(1,5):\n",
    "    if i<3:\n",
    "        mask = np.logical_or(mask,(ec[:,i]-np.mean(ec[:,i])) > (3 * np.std(ec[:,i])))\n",
    "    ax2.plot(ec[:,i],color=sns.color_palette()[i])\n",
    "    ax2.plot(np.arange(len(ec[:,i]))[mask],ec[mask,i],'o',mec='r')\n",
    "ax2.set_ylabel('All Other Coefficients')\n",
    "ax1.set_xlabel('Exposure Number, but Kind of Time')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./Figures/191113_outliers5c.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_files[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_range = np.arange(500,7000).astype(float)\n",
    "m_range = np.arange(45,75).astype(float)\n",
    "x_grid, m_grid = np.meshgrid(x_range,m_range)\n",
    "x_grid = x_grid.flatten()\n",
    "m_grid = m_grid.flatten()\n",
    "for k in range(3):\n",
    "    plt.figure()\n",
    "    plt.scatter(x_grid, m_grid, c=vv[k])\n",
    "    plt.title(\"eigenvector {:d}\".format(k))\n",
    "    plt.colorbar()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./Figures/191113_eigen5cvector{k}.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (python3/3.7.3)",
   "language": "python",
   "name": "module-python3-3.7.3-python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
