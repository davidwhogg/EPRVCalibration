{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing the Patch PCA Method on ThArs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits\n",
    "from astropy.time import Time\n",
    "from astropy.constants import c\n",
    "from scipy import interpolate\n",
    "from scipy.optimize import minimize, least_squares, curve_fit\n",
    "from mpfit import mpfit\n",
    "\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "from waveCal import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather files\n",
    "thar_files = glob('/mnt/home/lzhao/ceph/thar5*/ThAr_*.fits')\n",
    "num_files = len(thar_files)\n",
    "print(f'Number of files: {num_files}')\n",
    "\n",
    "hdus = fits.open(thar_files[0])\n",
    "t_spec = hdus[1].data['spectrum'].copy()\n",
    "t_errs = hdus[1].data['uncertainty'].copy()\n",
    "t_mask = hdus[1].data['pixel_mask'].copy()\n",
    "hdus.close()\n",
    "nord, npix = t_spec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ThAr line fit files\n",
    "thid_files  = glob('/mnt/home/lzhao/ceph/thid5*/ThAr_*.thid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort files by date:\n",
    "file_times = np.empty_like(thid_files,dtype='float')\n",
    "for i in range(len(thid_files)):\n",
    "    file_times[i] = os.path.basename(thid_files[i]).split('_')[-1][:-5]\n",
    "thid_files = np.array(thid_files)[np.argsort(file_times)]\n",
    "\n",
    "file_times = np.empty_like(thar_files,dtype='float')\n",
    "for i in range(len(thar_files)):\n",
    "    file_times[i] = os.path.basename(thar_files[i]).split('_')[-1][:-5]\n",
    "thar_files = np.array(thar_files)[np.argsort(file_times)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in all observed wavelengths into a big dictionary\n",
    "order_list = range(40,70)\n",
    "wavedict = {}\n",
    "for file_name in thid_files:\n",
    "    try:\n",
    "        x,m,w = readThid(file_name)\n",
    "    except ValueError:\n",
    "        continue\n",
    "    for nord in order_list:\n",
    "        if nord not in wavedict.keys():\n",
    "            wavedict[nord] = np.array([])\n",
    "        wavedict[nord] = np.unique(np.concatenate([wavedict[nord],w[m==nord]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat mode dictionary into a flat vector\n",
    "waves  = np.array([]).astype(float)\n",
    "orders = np.array([]).astype(int)\n",
    "for m in wavedict.keys():\n",
    "    waves = np.concatenate((waves, wavedict[m]))\n",
    "    orders = np.concatenate((orders, (np.zeros_like(wavedict[m])+m)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in x values to match order/mode lines\n",
    "x_values = np.empty((len(thid_files),len(waves)))\n",
    "x_values[:] = np.nan\n",
    "for i in tqdm(range(len(thid_files))):\n",
    "    file_name = thid_files[i]\n",
    "    try:\n",
    "        x,m,w = readThid(file_name)\n",
    "    except ValueError:\n",
    "        continue\n",
    "    for line in range(len(waves)):\n",
    "        I = m==orders[line]\n",
    "        if waves[line] in w[I]:\n",
    "            x_values[i,line] = x[I][w[I]==waves[line]] # hogg hates this line\n",
    "        else:\n",
    "            x_values[i,line] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where are we missing lines?\n",
    "for m in order_list:\n",
    "    ord_mask = orders==m\n",
    "    x_range = waves[ord_mask]\n",
    "    e_range = np.arange(len(thid_files)).astype(float)\n",
    "    x_grid, e_grid = np.meshgrid(x_range,e_range)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title(f'Order {m}')\n",
    "    plt.scatter(x_grid,e_grid,c=x_values[:,ord_mask],s=1)\n",
    "    plt.colorbar(label='Line Center [px]')\n",
    "    nan_mask = np.isnan(x_values[:,ord_mask])\n",
    "    plt.scatter(x_grid[nan_mask],e_grid[nan_mask],s=.5,c='r')\n",
    "    plt.xlabel('Wavelength')\n",
    "    plt.ylabel('Exposure Number-ish');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = sns.color_palette('RdYlBu',len(order_list))\n",
    "\n",
    "plt.figure()\n",
    "for i,nord in enumerate(order_list):\n",
    "    plt.plot(np.sum(np.isnan(x_values[:,orders==nord]),axis=1),color=colors[i])\n",
    "plt.xlabel('Exposure')\n",
    "\n",
    "plt.figure(figsize=(6.4*2,4.8))\n",
    "for i,nord in enumerate(order_list):\n",
    "    plt.plot(waves[orders==nord],\n",
    "             np.sum(np.isnan(x_values[:,orders==nord]),axis=0),color=colors[i])\n",
    "plt.xlabel('Wavelength')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of bad wavelengths\n",
    "x_values[x_values < 1] = np.nan\n",
    "good_lines = np.mean(np.isnan(x_values),axis=0) < 0.3\n",
    "\n",
    "# Trim everything\n",
    "orders = orders[good_lines]\n",
    "waves  = waves[good_lines]\n",
    "x_values = x_values[:,good_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.isnan(x_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of bad exposures\n",
    "good_exps = np.mean(np.isnan(x_values),axis=1) < 0.5\n",
    "print(thid_files[~good_exps])\n",
    "\n",
    "# Trim everything\n",
    "x_values = x_values[good_exps]\n",
    "exp_list = thid_files[good_exps]\n",
    "\n",
    "bad_mask = np.isnan(x_values)\n",
    "print(waves.shape, exp_list.shape, x_values.shape, bad_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.isnan(x_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = sns.color_palette('RdYlBu',len(order_list))\n",
    "\n",
    "plt.figure()\n",
    "for i,nord in enumerate(order_list):\n",
    "    plt.plot(np.sum(np.isnan(x_values[:,orders==nord]),axis=1),color=colors[i])\n",
    "plt.xlabel('Exposure')\n",
    "\n",
    "plt.figure(figsize=(6.4*2,4.8))\n",
    "for i,nord in enumerate(order_list):\n",
    "    plt.plot(waves[orders==nord],\n",
    "             np.sum(np.isnan(x_values[:,orders==nord]),axis=0),color=colors[i])\n",
    "plt.xlabel('Wavelength')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where are we missing lines?\n",
    "for m in order_list:\n",
    "    ord_mask = orders==m\n",
    "    x_range = waves[ord_mask]\n",
    "    e_range = np.arange(len(exp_list)).astype(float)\n",
    "    x_grid, e_grid = np.meshgrid(x_range,e_range)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title(f'Order {m}')\n",
    "    plt.scatter(x_grid,e_grid,c=x_values[:,ord_mask],s=1)\n",
    "    plt.colorbar(label='Line Center [px]')\n",
    "    nan_mask = np.isnan(x_values[:,ord_mask])\n",
    "    plt.scatter(x_grid[nan_mask],e_grid[nan_mask],s=.5,c='r')\n",
    "    plt.xlabel('Wavelength')\n",
    "    plt.ylabel('Exposure Number-ish');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patch bad data with running mean\n",
    "half_size = 4\n",
    "for i in range(x_values.shape[0]):\n",
    "    exp_range = [max((i-half_size,0)), min((i+half_size+1,x_values.shape[1]))]\n",
    "    run_med = np.nanmean(x_values[exp_range[0]:exp_range[1],:],axis=0)\n",
    "    x_values[i][bad_mask[i,:]] = run_med[bad_mask[i,:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterative PCA\n",
    "num_iters = 50\n",
    "\n",
    "iter_x_values = np.zeros((num_iters,*x_values.shape))\n",
    "iter_vvs = np.zeros((num_iters,*x_values.shape))\n",
    "\n",
    "for i in tqdm(range(num_iters)):\n",
    "    # Redefine mean\n",
    "    mean_x_values = np.mean(x_values,axis=0)\n",
    "    # Run PCA\n",
    "    uu,ss,vv = np.linalg.svd(x_values-mean_x_values,full_matrices=False)\n",
    "    iter_vvs[i] = vv.copy()\n",
    "\n",
    "    # Repatch bad data with K=2 PCA reconstruction\n",
    "    pca_patch = np.dot((uu*ss)[:,0:2],vv[0:2])\n",
    "    x_values[bad_mask] = (pca_patch+mean_x_values)[bad_mask]\n",
    "    iter_x_values[i] = x_values.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do the eigenvectors compare with each iteration\n",
    "plt.figure(figsize=(6.4*3,4.8*2))\n",
    "ax1 = plt.subplot(231)\n",
    "plt.title('Eigenvector 0')\n",
    "plt.ylabel('Eigenvector Value')\n",
    "plt.xlabel('Fraction of Order')\n",
    "ax2 = plt.subplot(232)\n",
    "plt.title('Eigenvector 1')\n",
    "plt.xlabel('Fraction of Order')\n",
    "ax3 = plt.subplot(233)\n",
    "plt.title('Eigenvector 2')\n",
    "plt.xlabel('Fraction of Order')\n",
    "ax4 = plt.subplot(234)\n",
    "plt.title('Eigenvector 3')\n",
    "plt.ylabel('Eigenvector Value')\n",
    "plt.xlabel('Fraction of Order')\n",
    "ax5 = plt.subplot(235)\n",
    "plt.title('Eigenvector 4')\n",
    "plt.xlabel('Fraction of Order')\n",
    "ax6 = plt.subplot(236)\n",
    "plt.title('Eigenvector 5')\n",
    "plt.xlabel('Fraction of Order')\n",
    "colors = sns.color_palette(\"RdYlBu\",len(order_list))\n",
    "for i in tqdm(range(num_iters)):\n",
    "    for j, nord in enumerate(order_list):\n",
    "        ax1.plot(np.linspace(0,1,np.sum(orders==nord)),\n",
    "                 iter_vvs[i][0][orders==nord],color=colors[j])\n",
    "        ax2.plot(np.linspace(0,1,np.sum(orders==nord)),\n",
    "                 iter_vvs[i][1][orders==nord],color=colors[j])\n",
    "        ax3.plot(np.linspace(0,1,np.sum(orders==nord)),\n",
    "                 iter_vvs[i][2][orders==nord],color=colors[j])\n",
    "        ax4.plot(np.linspace(0,1,np.sum(orders==nord)),\n",
    "                 iter_vvs[i][3][orders==nord],color=colors[j])\n",
    "        ax5.plot(np.linspace(0,1,np.sum(orders==nord)),\n",
    "                 iter_vvs[i][4][orders==nord],color=colors[j])\n",
    "        ax6.plot(np.linspace(0,1,np.sum(orders==nord)),\n",
    "                 iter_vvs[i][5][orders==nord],color=colors[j])\n",
    "plt.savefig('./Figures/191121_ThAreigenVs.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are the bad pixel values converging?\n",
    "plt.figure()\n",
    "plt.title('Convergence in Bad Pixel Values')\n",
    "plt.ylabel('Normalized Pixel Value')\n",
    "plt.xlabel('Iteration')\n",
    "plt.plot(iter_x_values[:,bad_mask]/iter_x_values[-1,bad_mask],'.-',alpha=0.3);\n",
    "plt.savefig('./Figures/191121_ThArbadPixConvergence.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State of the SVD eigenvectors\n",
    "plt.figure()\n",
    "plt.title('SVD Eigenvectors')\n",
    "plt.xlabel('Element Number')\n",
    "plt.ylabel('Log Value')\n",
    "plt.step(np.arange(16),np.log(ss[:16]))\n",
    "plt.savefig('./Figures/191121_ThArssStep.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
