{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Different K Values and Interpolation Schemes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Waiting to run to:\n",
    "1. make sure waveCal is no longer in flux\n",
    "1. decide which test (lfc->thar or lfc->lfc) is a better metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits\n",
    "from astropy.time import Time\n",
    "from astropy.constants import c\n",
    "from scipy import interpolate\n",
    "from scipy.optimize import minimize, least_squares, curve_fit\n",
    "from mpfit import mpfit\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "from waveCal import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather files\n",
    "\n",
    "# LFC\n",
    "lfc_files = glob('/mnt/home/lzhao/ceph/lfc5*/LFC_*.fits')\n",
    "ckpt_files = glob('/mnt/home/lzhao/ceph/ckpt5*/LFC_19*.npy')\n",
    "lfc_files, lfc_times = sortFiles(lfc_files, get_mjd=True)\n",
    "ckpt_files = sortFiles(ckpt_files)\n",
    "num_lfc_files = len(lfc_files)\n",
    "\n",
    "hdus = fits.open(lfc_files[0])\n",
    "t_spec = hdus[1].data['spectrum'].copy()\n",
    "t_errs = hdus[1].data['uncertainty'].copy()\n",
    "t_mask = hdus[1].data['pixel_mask'].copy()\n",
    "hdus.close()\n",
    "nord, npix = t_spec.shape\n",
    "\n",
    "lfc_orders = range(45,76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ThAr\n",
    "thar_files = glob('/mnt/home/lzhao/ceph/thar5*/ThAr_*.fits')\n",
    "thid_files  = glob('/mnt/home/lzhao/ceph/thid5*/ThAr_*.thid')\n",
    "thar_files, thar_times = sortFiles(thar_files, get_mjd=True)\n",
    "thar_files = thar_files[1:] # First file is from before LFCs\n",
    "thar_times = thar_times[1:]\n",
    "thid_files = sortFiles(thid_files) [1:]\n",
    "num_thar_files = len(thar_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate Training and Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "# Make sure validation exposures are not first or last exposure\n",
    "valid_idx = np.random.choice(num_lfc_files-2, num_lfc_files//10, replace=False)+1\n",
    "\n",
    "lfc_train = np.delete(ckpt_files,valid_idx)\n",
    "lfc_times_train = np.delete(lfc_times,valid_idx)\n",
    "time_sort = np.argsort(lfc_times_train)\n",
    "lfc_train = lfc_train[time_sort]\n",
    "lfc_times_train = lfc_times_train[time_sort]\n",
    "\n",
    "lfc_valid = ckpt_files[valid_idx]\n",
    "lfc_times_valid = lfc_times[valid_idx]\n",
    "time_sort = np.argsort(lfc_times_valid)\n",
    "lfc_valid = lfc_valid[time_sort]\n",
    "lfc_times_valid = lfc_times_valid[time_sort]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "valid_idx = np.random.choice(num_thar_files-2, num_thar_files//10, replace=False)+1\n",
    "\n",
    "thar_train = np.delete(thid_files,valid_idx)\n",
    "thar_times_train = np.delete(thar_times,valid_idx)\n",
    "time_sort = np.argsort(thar_times_train)\n",
    "thar_train = thar_train[time_sort]\n",
    "thar_times_train = thar_times_train[time_sort]\n",
    "\n",
    "thar_valid = thid_files[valid_idx]\n",
    "thar_times_valid = thar_times[valid_idx]\n",
    "time_sort = np.argsort(thar_times_valid)\n",
    "thar_valid = thar_train[time_sort]\n",
    "thar_times_valid = thar_times_valid[time_sort]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different K Values for PCA Patching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_patch2_train = pickle.load(open('./191205_ckptPatch9_train.pkl','rb'))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ckpt_patch4_train = patchAndDenoise(lfc_train, file_times=lfc_times_train,\n",
    "    K=4, num_iters=50, return_iters=False, running_window=9,\n",
    "    line_cutoff=0.5, file_cutoff=0.5, fast_pca=False, verbose=True)\n",
    "pickle.dump(ckpt_patch4_train, open( \"./191206_ckptPatch4_train.pkl\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ckpt_patch8_train = patchAndDenoise(lfc_train, file_times=lfc_times_train,\n",
    "    K=8, num_iters=50, return_iters=False, running_window=9,\n",
    "    line_cutoff=0.5, file_cutoff=0.5, fast_pca=False, verbose=True)\n",
    "pickle.dump(ckpt_patch8_train, open( \"./191206_ckptPatch8_train.pkl\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ckpt_patch16_train = patchAndDenoise(lfc_train, file_times=lfc_times_train,\n",
    "    K=16, num_iters=50, return_iters=False, running_window=9,\n",
    "    line_cutoff=0.5, file_cutoff=0.5, fast_pca=False, verbose=True)\n",
    "pickle.dump(ckpt_patch16_train, open( \"./191206_ckptPatch16_train.pkl\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_patch4_train = pickle.load(open('./191206_ckptPatch4_train.pkl','rb'))\n",
    "ckpt_patch8_train = pickle.load(open('./191206_ckptPatch8_train.pkl','rb'))\n",
    "ckpt_patch16_train = pickle.load(open('./191206_ckptPatch16_train.pkl','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LFC Validation Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoised_xs = evalWaveSol(lfc_times_valid, ckpt_patch2_train, t_intp_deg=3)\n",
    "m = ckpt_patch2_train['orders'].copy()\n",
    "w = ckpt_patch2_train['waves'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfc_fits = []\n",
    "lfc_shifts = np.array([],dtype=float)\n",
    "ckpt_x = []\n",
    "ckpt_m = []\n",
    "ckpt_w = []\n",
    "for file_num in tqdm(range(len(lfc_valid))):\n",
    "    file_name = lfc_valid[file_num]\n",
    "    try:\n",
    "        newx,newm,neww,newe = readParams(file_name)\n",
    "    except ValueError as err:\n",
    "        continue\n",
    "    \n",
    "    w_fit = interp_train_and_predict(newx, newm,\n",
    "                                     denoised_xs[file_num], m, w,\n",
    "                                     e=newe, interp_deg=3)\n",
    "    \n",
    "    ckpt_x.append(newx)\n",
    "    ckpt_m.append(newm)\n",
    "    ckpt_w.append(neww)\n",
    "    lfc_fits.append(w_fit)\n",
    "    good_mask = np.isfinite(w_fit)\n",
    "    lfc_shifts = np.concatenate([lfc_shifts,\n",
    "                                 (w_fit[good_mask]-neww[good_mask])/neww[good_mask]*c.value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rv_shift = lfc_shifts.flatten()\n",
    "rv_shift = rv_shift[abs(rv_shift)<25]\n",
    "\n",
    "plt.figure()\n",
    "plt.title(f'LFC Training and Validation: K=2, All {len(lfc_times_valid)} Validation Exposures')\n",
    "plt.xlabel('Predicted - Fit [m/s]')\n",
    "plt.ylabel('Frequency')\n",
    "plt.hist(rv_shift,50);\n",
    "plt.axvline(np.mean(rv_shift),color='r',label='Mean: {:.3} m/s'.format(np.mean(rv_shift)))\n",
    "plt.axvline(np.median(rv_shift),color='g',label='Median: {:.3} m/s'.format(np.median(rv_shift)))\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('./Figures/191206_lfcTnV2.png')\n",
    "print(np.std(rv_shift))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoised_xs = evalWaveSol(lfc_times_valid, ckpt_patch4_train, t_intp_deg=3)\n",
    "m = ckpt_patch4_train['orders'].copy()\n",
    "w = ckpt_patch4_train['waves'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfc_fits = []\n",
    "lfc_shifts = np.array([],dtype=float)\n",
    "ckpt_x = []\n",
    "ckpt_m = []\n",
    "ckpt_w = []\n",
    "for file_num in tqdm(range(len(lfc_valid))):\n",
    "    file_name = lfc_valid[file_num]\n",
    "    try:\n",
    "        newx,newm,neww,newe = readParams(file_name)\n",
    "    except ValueError as err:\n",
    "        continue\n",
    "    \n",
    "    w_fit = interp_train_and_predict(newx, newm,\n",
    "                                     denoised_xs[file_num], m, w,\n",
    "                                     e=newe, interp_deg=3)\n",
    "    \n",
    "    ckpt_x.append(newx)\n",
    "    ckpt_m.append(newm)\n",
    "    ckpt_w.append(neww)\n",
    "    lfc_fits.append(w_fit)\n",
    "    good_mask = np.isfinite(w_fit)\n",
    "    lfc_shifts = np.concatenate([lfc_shifts,\n",
    "                                 (w_fit[good_mask]-neww[good_mask])/neww[good_mask]*c.value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rv_shift = lfc_shifts.flatten()\n",
    "rv_shift = rv_shift[abs(rv_shift)<25]\n",
    "\n",
    "plt.figure()\n",
    "plt.title(f'LFC Training and Validation: K=4, All {len(lfc_times_valid)} Validation Exposures')\n",
    "plt.xlabel('Predicted - Fit [m/s]')\n",
    "plt.ylabel('Frequency')\n",
    "plt.hist(rv_shift,50);\n",
    "plt.axvline(np.mean(rv_shift),color='r',label='Mean: {:.3} m/s'.format(np.mean(rv_shift)))\n",
    "plt.axvline(np.median(rv_shift),color='g',label='Median: {:.3} m/s'.format(np.median(rv_shift)))\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('./Figures/191206_lfcTnV4.png')\n",
    "print(np.std(rv_shift))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoised_xs = evalWaveSol(lfc_times_valid, ckpt_patch8_train, t_intp_deg=3)\n",
    "m = ckpt_patch8_train['orders'].copy()\n",
    "w = ckpt_patch8_train['waves'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfc_fits = []\n",
    "lfc_shifts = np.array([],dtype=float)\n",
    "ckpt_x = []\n",
    "ckpt_m = []\n",
    "ckpt_w = []\n",
    "for file_num in tqdm(range(len(lfc_valid))):\n",
    "    file_name = lfc_valid[file_num]\n",
    "    try:\n",
    "        newx,newm,neww,newe = readParams(file_name)\n",
    "    except ValueError as err:\n",
    "        continue\n",
    "    \n",
    "    w_fit = interp_train_and_predict(newx, newm,\n",
    "                                     denoised_xs[file_num], m, w,\n",
    "                                     e=newe, interp_deg=3)\n",
    "    \n",
    "    ckpt_x.append(newx)\n",
    "    ckpt_m.append(newm)\n",
    "    ckpt_w.append(neww)\n",
    "    lfc_fits.append(w_fit)\n",
    "    good_mask = np.isfinite(w_fit)\n",
    "    lfc_shifts = np.concatenate([lfc_shifts,\n",
    "                                 (w_fit[good_mask]-neww[good_mask])/neww[good_mask]*c.value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rv_shift = lfc_shifts.flatten()\n",
    "rv_shift = rv_shift[abs(rv_shift)<25]\n",
    "\n",
    "plt.figure()\n",
    "plt.title(f'LFC Training and Validation: K=8, All {len(lfc_times_valid)} Validation Exposures')\n",
    "plt.xlabel('Predicted - Fit [m/s]')\n",
    "plt.ylabel('Frequency')\n",
    "plt.hist(rv_shift,50);\n",
    "plt.axvline(np.mean(rv_shift),color='r',label='Mean: {:.3} m/s'.format(np.mean(rv_shift)))\n",
    "plt.axvline(np.median(rv_shift),color='g',label='Median: {:.3} m/s'.format(np.median(rv_shift)))\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('./Figures/191206_lfcTnV8.png')\n",
    "print(np.std(rv_shift))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoised_xs = evalWaveSol(lfc_times_valid, ckpt_patch16_train, t_intp_deg=3)\n",
    "m = ckpt_patch16_train['orders'].copy()\n",
    "w = ckpt_patch16_train['waves'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfc_fits = []\n",
    "lfc_shifts = np.array([],dtype=float)\n",
    "ckpt_x = []\n",
    "ckpt_m = []\n",
    "ckpt_w = []\n",
    "for file_num in tqdm(range(len(lfc_valid))):\n",
    "    file_name = lfc_valid[file_num]\n",
    "    try:\n",
    "        newx,newm,neww,newe = readParams(file_name)\n",
    "    except ValueError as err:\n",
    "        continue\n",
    "    \n",
    "    w_fit = interp_train_and_predict(newx, newm,\n",
    "                                     denoised_xs[file_num], m, w,\n",
    "                                     e=newe, interp_deg=3)\n",
    "    \n",
    "    ckpt_x.append(newx)\n",
    "    ckpt_m.append(newm)\n",
    "    ckpt_w.append(neww)\n",
    "    lfc_fits.append(w_fit)\n",
    "    good_mask = np.isfinite(w_fit)\n",
    "    lfc_shifts = np.concatenate([lfc_shifts,\n",
    "                                 (w_fit[good_mask]-neww[good_mask])/neww[good_mask]*c.value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rv_shift = lfc_shifts.flatten()\n",
    "rv_shift = rv_shift[abs(rv_shift)<25]\n",
    "\n",
    "plt.figure()\n",
    "plt.title(f'LFC Training and Validation: K=16, All {len(lfc_times_valid)} Validation Exposures')\n",
    "plt.xlabel('Predicted - Fit [m/s]')\n",
    "plt.ylabel('Frequency')\n",
    "plt.hist(rv_shift,50);\n",
    "plt.axvline(np.mean(rv_shift),color='r',label='Mean: {:.3} m/s'.format(np.mean(rv_shift)))\n",
    "plt.axvline(np.median(rv_shift),color='g',label='Median: {:.3} m/s'.format(np.median(rv_shift)))\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('./Figures/191206_lfcTnV16.png')\n",
    "print(np.std(rv_shift))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different x_direction Interpolation Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_intps = [2,3,'lsq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different t_direction Interpolation Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_intps = [0,1,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_patch_train = pickle.load(open('./191205_ckptPatch9_train.pkl','rb'))\n",
    "thid_patch_train = pickle.load(open('./191205_thidPatch15_train.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_patch_train['bad_mask'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(ckpt_patch_train['bad_mask'])/1132/35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.sum(ckpt_patch_train['bad_mask'],axis=1),10);\n",
    "plt.xlabel('Missing Lines in One Exposure')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LFC Validation Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoised_xs = evalWaveSol(lfc_times_valid, ckpt_patch_train, t_intp_deg=3)\n",
    "m = ckpt_patch_train['orders'].copy()\n",
    "w = ckpt_patch_train['waves'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfc_fits3 = []\n",
    "lfc_shifts3 = np.array([],dtype=float)\n",
    "ckpt_w3 = []\n",
    "for file_num in tqdm(range(len(lfc_valid))):\n",
    "    file_name = lfc_valid[file_num]\n",
    "    try:\n",
    "        newx,newm,neww,newe = readParams(file_name)\n",
    "    except ValueError as err:\n",
    "        continue\n",
    "    \n",
    "    w_fit = interp_train_and_predict(newx, newm,\n",
    "                                     denoised_xs[file_num], m, w,\n",
    "                                     e=newe, interp_deg=3)\n",
    "    lfc_fits3.append(w_fit)\n",
    "    good_mask = np.isfinite(w_fit)\n",
    "    ckpt_w3.append(neww)\n",
    "    lfc_shifts3 = np.concatenate([lfc_shifts3,\n",
    "                                 (w_fit[good_mask]-neww[good_mask])/neww[good_mask]*c.value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoised_xs = evalWaveSol(lfc_times_valid, ckpt_patch_train, t_intp_deg=0)\n",
    "m = ckpt_patch_train['orders'].copy()\n",
    "w = ckpt_patch_train['waves'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfc_fits0 = []\n",
    "lfc_shifts0 = np.array([],dtype=float)\n",
    "ckpt_w0 = []\n",
    "for file_num in tqdm(range(len(lfc_valid))):\n",
    "    file_name = lfc_valid[file_num]\n",
    "    try:\n",
    "        newx,newm,neww,newe = readParams(file_name)\n",
    "    except ValueError as err:\n",
    "        continue\n",
    "    \n",
    "    w_fit = interp_train_and_predict(newx, newm,\n",
    "                                     denoised_xs[file_num], m, w,\n",
    "                                     e=newe, interp_deg=3)\n",
    "    lfc_fits0.append(w_fit)\n",
    "    good_mask = np.isfinite(w_fit)\n",
    "    ckpt_w0.append(neww)\n",
    "    lfc_shifts0 = np.concatenate([lfc_shifts0,\n",
    "                                 (w_fit[good_mask]-neww[good_mask])/neww[good_mask]*c.value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoised_xs = evalWaveSol(lfc_times_valid, ckpt_patch_train, t_intp_deg=1)\n",
    "m = ckpt_patch_train['orders'].copy()\n",
    "w = ckpt_patch_train['waves'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfc_fits1 = []\n",
    "lfc_shifts1 = np.array([],dtype=float)\n",
    "ckpt_w1 = []\n",
    "for file_num in tqdm(range(len(lfc_valid))):\n",
    "    file_name = lfc_valid[file_num]\n",
    "    try:\n",
    "        newx,newm,neww,newe = readParams(file_name)\n",
    "    except ValueError as err:\n",
    "        continue\n",
    "    \n",
    "    w_fit = interp_train_and_predict(newx, newm,\n",
    "                                     denoised_xs[file_num], m, w,\n",
    "                                     e=newe, interp_deg=3)\n",
    "    lfc_fits1.append(w_fit)\n",
    "    good_mask = np.isfinite(w_fit)\n",
    "    ckpt_w1.append(neww)\n",
    "    lfc_shifts1 = np.concatenate([lfc_shifts1,\n",
    "                                 (w_fit[good_mask]-neww[good_mask])/neww[good_mask]*c.value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(newe*500,50);\n",
    "plt.xlabel('Error [m/s]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6.4*3,4.8))\n",
    "plt.subplot(131)\n",
    "plt.title('Cubic Spline')\n",
    "plt.xlabel('Predicted - Fit [m/s]')\n",
    "plt.ylabel('Frequency')\n",
    "rv_shift = lfc_shifts3.flatten()\n",
    "rv_shift = rv_shift[abs(rv_shift)<25]\n",
    "plt.hist(rv_shift,50);\n",
    "plt.axvline(np.mean(rv_shift),color='r',label='Mean: {:.3} m/s'.format(np.mean(rv_shift)))\n",
    "plt.axvline(np.median(rv_shift),color='g',label='Median: {:.3} m/s'.format(np.median(rv_shift)))\n",
    "plt.axvline(np.mean(rv_shift)-np.std(rv_shift),color='k',label='$\\\\sigma$: {:.3} m/s'.format(np.std(rv_shift)))\n",
    "plt.axvline(np.mean(rv_shift)+np.std(rv_shift),color='k')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.title('Linear Interpolation')\n",
    "plt.xlabel('Predicted - Fit [m/s]')\n",
    "plt.ylabel('Frequency')\n",
    "rv_shift = lfc_shifts1.flatten()\n",
    "rv_shift = rv_shift[abs(rv_shift)<25]\n",
    "plt.hist(rv_shift,50);\n",
    "plt.axvline(np.mean(rv_shift),color='r',label='Mean: {:.3} m/s'.format(np.mean(rv_shift)))\n",
    "plt.axvline(np.median(rv_shift),color='g',label='Median: {:.3} m/s'.format(np.median(rv_shift)))\n",
    "plt.axvline(np.mean(rv_shift)-np.std(rv_shift),color='k',label='$\\\\sigma$: {:.3} m/s'.format(np.std(rv_shift)))\n",
    "plt.axvline(np.mean(rv_shift)+np.std(rv_shift),color='k')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.title('Nearest Neighbor')\n",
    "plt.xlabel('Predicted - Fit [m/s]')\n",
    "plt.ylabel('Frequency')\n",
    "rv_shift = lfc_shifts0.flatten()\n",
    "rv_shift = rv_shift[abs(rv_shift)<25]\n",
    "plt.hist(rv_shift,50);\n",
    "plt.axvline(np.mean(rv_shift),color='r',label='Mean: {:.3} m/s'.format(np.mean(rv_shift)))\n",
    "plt.axvline(np.median(rv_shift),color='g',label='Median: {:.3} m/s'.format(np.median(rv_shift)))\n",
    "plt.axvline(np.mean(rv_shift)-np.std(rv_shift),color='k',label='$\\\\sigma$: {:.3} m/s'.format(np.std(rv_shift)))\n",
    "plt.axvline(np.mean(rv_shift)+np.std(rv_shift),color='k')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('./Figures/191205_lfcTnV.png')\n",
    "print(np.std(rv_shift))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6.4*3,4.8))\n",
    "plt.subplot(131)\n",
    "plt.title('Cubic Spline')\n",
    "plt.xlabel('Predicted - Fit [m/s]')\n",
    "plt.ylabel('Frequency')\n",
    "colors = sns.color_palette('plasma',len(lfc_times_valid))\n",
    "for i, t in enumerate(lfc_times_valid):\n",
    "    resid = lfc_fits3[i] - ckpt_w3[i]\n",
    "    rv_shift = resid/ckpt_w3[i]*c.value\n",
    "    plt.hist(rv_shift,np.arange(-25,26,2.5),histtype='step',color=colors[i])\n",
    "plt.xlim(-25,25)\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.title('Linear Interpolation')\n",
    "plt.xlabel('Predicted - Fit [m/s]')\n",
    "plt.ylabel('Frequency')\n",
    "colors = sns.color_palette('plasma',len(lfc_times_valid))\n",
    "for i, t in enumerate(lfc_times_valid):\n",
    "    resid = lfc_fits1[i] - ckpt_w1[i]\n",
    "    rv_shift = resid/ckpt_w1[i]*c.value\n",
    "    plt.hist(rv_shift,np.arange(-25,26,2.5),histtype='step',color=colors[i])\n",
    "plt.xlim(-25,25)\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.title('Nearest Neighbor')\n",
    "plt.xlabel('Predicted  Fit [m/s]')\n",
    "plt.ylabel('Frequency')\n",
    "colors = sns.color_palette('plasma',len(lfc_times_valid))\n",
    "for i, t in enumerate(lfc_times_valid):\n",
    "    resid = lfc_fits0[i] - ckpt_w0[i]\n",
    "    rv_shift = resid/ckpt_w0[i]*c.value\n",
    "    plt.hist(rv_shift,np.arange(-25,26,2.5),histtype='step',color=colors[i])\n",
    "plt.xlim(-25,25)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title('LFC Training and Validation: Exp {}'.format(Time(t,format='mjd').isot))\n",
    "plt.xlabel('Predicted - Fit [m/s]')\n",
    "plt.ylabel('Frequency')\n",
    "resid = lfc_fits[1] - ckpt_w[1]\n",
    "rv_shift = resid/ckpt_w[1]*c.value\n",
    "plt.hist(rv_shift,50);\n",
    "plt.axvline(np.nanmean(rv_shift),color='r',label='Mean: {:.3} m/s'.format(np.nanmean(rv_shift)))\n",
    "plt.axvline(np.nanmedian(rv_shift),color='g',label='Median: {:.3} m/s'.format(np.nanmedian(rv_shift)))\n",
    "plt.legend()\n",
    "plt.xlim(-25,25)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'./Figures/191205_lfcTnV6.png')\n",
    "print(np.nanstd(rv_shift))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ThAr Validation Test, t_intp=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoised_xs = evalWaveSol(thar_times_valid, thid_patch_train, t_intp_deg=1)\n",
    "m = thid_patch_train['orders'].copy()\n",
    "w = thid_patch_train['waves'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thar_fits = []\n",
    "thar_shifts = np.array([],dtype=float)\n",
    "thid_x = []\n",
    "thid_m = []\n",
    "thid_w = []\n",
    "for file_num in tqdm(range(len(thar_valid))):\n",
    "    file_name = thar_valid[file_num]\n",
    "    try:\n",
    "        newx,newm,neww = readThid(file_name)\n",
    "    except ValueError as err:\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        w_fit = interp_train_and_predict(newx, newm,\n",
    "                                         denoised_xs[file_num], m, w,\n",
    "                                         e=None, interp_deg=3)\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    thid_x.append(newx)\n",
    "    thid_m.append(newm)\n",
    "    thid_w.append(neww)\n",
    "    thar_fits.append(w_fit)\n",
    "    good_mask = np.isfinite(w_fit)\n",
    "    thar_shifts = np.concatenate([thar_shifts,\n",
    "                                 (w_fit[good_mask]-neww[good_mask])/neww[good_mask]*c.value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rv_shift = thar_shifts.flatten()\n",
    "innie_mask = abs(rv_shift) < 2000\n",
    "\n",
    "plt.figure()\n",
    "plt.title('ThAr Training and Validation')\n",
    "plt.xlabel('Predicted - Fit [m/s]')\n",
    "plt.ylabel('Frequency')\n",
    "plt.hist(rv_shift[innie_mask],50);\n",
    "plt.tight_layout()\n",
    "plt.savefig('./Figures/191205_tharTnV.png')\n",
    "print(np.std(rv_shift[innie_mask]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
