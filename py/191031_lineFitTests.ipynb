{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPRES Wavelength Solution Characterization\n",
    "\n",
    "At present (Oct. 31, 2019), the EXPRES wavelength solution has been carried out by scanning each order, finding peaks, and fitting each of these peaks to a Guassian.  If these peaks and subsequent fits succeed in a series of checks, they are deemed LFC lines and loaded into a list along with the supposed wavelength of the LFC according to the LFC equation and an initial guess using the ThAr wavelength solution.\n",
    "\n",
    "A 2D polynomial is then fit to pixel of line center, order, and wavelength (with wavelength being the dependent variable).  This polynomial is evaluated at all pixels to produce a wavelength solution.\n",
    "\n",
    "This notebook sets up that frame work and then explores alternative ways of constructing a wavelength solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from numpy.polynomial.polynomial import polyvander2d, polyval2d\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits\n",
    "from astropy.constants import c\n",
    "from scipy.optimize import curve_fit, least_squares\n",
    "from scipy.signal import argrelmin\n",
    "from scipy.interpolate import UnivariateSpline, interp1d\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load example LFC and checkpoint information\n",
    "hdus = fits.open('./LFCs/LFC_190923.1071.fits')\n",
    "spec = hdus[1].data['spectrum'].copy()\n",
    "head = hdus[0].header.copy()\n",
    "hdus.close()\n",
    "\n",
    "# Checkpoint files include information about the fits to each line,\n",
    "# their wavelength, and a few quality values\n",
    "info = np.load('./Checkpoints/LFC_190923.1071.npy',allow_pickle=True)[()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example plot of how an LFC looks and the ofund line centers\n",
    "plt.figure(figsize=(6.4*2,4.8))\n",
    "plt.title('Example Spectrum')\n",
    "plt.xlabel('Pixel')\n",
    "plt.ylabel('Extracted Value')\n",
    "plt.plot(spec[60])\n",
    "for i in info['params'][60][:,1]:\n",
    "    plt.axvline(i,color='.75')\n",
    "plt.xlim(3000,3250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readParams(file_name):\n",
    "    \"\"\"\n",
    "    Given the file name of a check_point file,\n",
    "    load in all relevant data into 1D vectors\n",
    "    \n",
    "    Returns vectors for line center in pixel (x),\n",
    "    order (y), error in line center fit in pixels (e),\n",
    "    and wavelength of line (w)\n",
    "    \"\"\"\n",
    "    info = np.load(file_name,allow_pickle=True)[()]\n",
    "    # Assemble information into \"fit-able\" form\n",
    "    lines = [p[:,1] for p in info['params'] if p is not None]\n",
    "    errs = [np.sqrt(cov[:,1,1]) for cov in info['cov'] if cov is not None]\n",
    "    ordrs = [o for o in np.arange(len(spec)) if info['params'][o] is not None]\n",
    "    waves = [w for w in info['wvln'] if w is not None]\n",
    "    # I believe, but am not sure, that the wavelengths are multiplied by order\n",
    "    # to separate them from when orders overlap at the edges\n",
    "    waves = [wvln for order, wvln in zip(ordrs,waves)]\n",
    "    ordrs = [np.ones_like(x) * m for m,x in zip(ordrs, lines)]\n",
    "\n",
    "    x = np.concatenate(lines)\n",
    "    y = np.concatenate(ordrs)\n",
    "    e = np.concatenate(errs)\n",
    "    w = np.concatenate(waves)\n",
    "    # Note: default of pipeline includes ThAr lines, which we're not including here\n",
    "    \n",
    "    return (x,y,e,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,e,w = readParams('./Checkpoints/LFC_190923.1071.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title('Fit Parameters')\n",
    "plt.xlabel('Pixel')\n",
    "plt.ylabel('Order')\n",
    "plt.scatter(x,y,c=w/y)\n",
    "plt.colorbar(label='Wavelength [nm]');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6.4*3,4.8))\n",
    "plt.title('Error in Line Centers')\n",
    "plt.xlabel('Pixel')\n",
    "plt.ylabel('Order')\n",
    "plt.scatter(x,y,c=e,marker='|',cmap='Spectral_r')\n",
    "plt.colorbar(label='Error in Pixel');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial fit in the pipeline\n",
    "def poly_fit_2d(x, y, data, deg=9, w=None):\n",
    "    \"\"\"\n",
    "    Calculate the 2D polynomial fit coefficients assuming that the\n",
    "    1D solution in x is approximately the correct answer.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : ndarray\n",
    "        The x positions\n",
    "    y : ndarray\n",
    "        The y postiions\n",
    "    data : ndarray\n",
    "        The data at each (x, y)\n",
    "    deg : int or tuple\n",
    "        The polynomial degree to fit. If a tuple: (deg_x, deg_y)\n",
    "    w : ndarray\n",
    "        A weight for each data point\n",
    "    \"\"\"\n",
    "    if len(x) < 1:\n",
    "        return None\n",
    "\n",
    "    if w is None:\n",
    "        w = np.ones_like(data)\n",
    "\n",
    "    w = np.where(np.isnan(data) | np.isnan(w), 0, w)\n",
    "\n",
    "    if isinstance(deg, int):\n",
    "        deg = (deg, deg)\n",
    "\n",
    "    deg_x, deg_y = deg\n",
    "\n",
    "    def resid(coeffs):\n",
    "        \"\"\"The residual cost function for least_squares\"\"\"\n",
    "        # Reshape the coefficient array into a matrix usable by polyval2d\n",
    "        coeff_arr = coeffs.reshape(deg_x+1, -1)\n",
    "        return (data - polyval2d(x, y, coeff_arr)) * w\n",
    "\n",
    "    # Intialize the coefficients with the 1D polynomial fit\n",
    "    coeffs = np.polyfit(x, data, deg=deg_x, w=w)[::-1, np.newaxis]\n",
    "\n",
    "    # Gradually add higher order y parameters until the full 2D polynomial is fit\n",
    "    for width in range(2, deg_y+2):\n",
    "        guess = np.zeros((deg_x+1, width))\n",
    "        guess[:, :-1] = coeffs\n",
    "        result = least_squares(resid, guess.flatten(), method='lm')\n",
    "        coeffs = result.x.reshape(deg_x+1, -1)\n",
    "\n",
    "    return coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing a design matrix for polynomial fitting instead\n",
    "def mkBlob(x, m, deg):\n",
    "    \"\"\"\n",
    "    x: pixel\n",
    "    m: order\n",
    "    deg: degree of polynomial\n",
    "    \"\"\"\n",
    "    # shift the data to center around the mean and have lower values\n",
    "    xshift = np.mean(x)\n",
    "    mshift = np.mean(m)\n",
    "    xt = (x - xshift)\n",
    "    mt = (m - mshift)\n",
    "    scales = []\n",
    "    for i in range(deg+1):\n",
    "        for j in range(deg+1-i):\n",
    "            vec = xt ** i * mt ** j\n",
    "            # Scale the data so they cover about the same range of values\n",
    "            scales.append(np.sqrt(vec.dot(vec)))\n",
    "    # Values of shift and scale must be catalogue\n",
    "    # in order to keep the fitted coefficients interpretable\n",
    "    return (deg, xshift, mshift, scales)\n",
    "            \n",
    "def mkDesignMatrix(x, m, blob):\n",
    "    \"\"\"\n",
    "    blob: output of mkBlob()\n",
    "    BUG: DUPLICATED CODE WITH mkBlob()\n",
    "    \"\"\"\n",
    "    deg, xshift, mshift, scales = blob\n",
    "    xt = (x - xshift)\n",
    "    mt = (m - mshift)\n",
    "    matrix = []\n",
    "    k = 0\n",
    "    for i in range(deg+1):\n",
    "        for j in range(deg+1-i):\n",
    "            vec = xt ** i * mt ** j\n",
    "            matrix.append(vec / scales[k])\n",
    "            k += 1\n",
    "    return np.array(matrix).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(data, M, weights):\n",
    "    \"\"\"\n",
    "    return coefficients of the linear fit!\n",
    "    \"\"\"\n",
    "    MTM = M.T.dot(weights[:,None] * M)\n",
    "    print(\"fit(): condition number: {:.2e}\".format(np.linalg.cond(MTM)))\n",
    "    MTy = M.T.dot(weights * data)\n",
    "    return np.linalg.solve(MTM, MTy)\n",
    "\n",
    "def predict(newx, newm, blob, coeffs):\n",
    "    \"\"\"\n",
    "    use coefficients to predict new wavelengths\n",
    "    \"\"\"\n",
    "    Mnew = mkDesignMatrix(newx, newm, blob)\n",
    "    return Mnew.dot(coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results with `poly_fit_2d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit\n",
    "coeffs8 = poly_fit_2d(x,y,w,deg=8,w=1/e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual Plot\n",
    "plt.figure()\n",
    "plt.title('Residual Plot (8th Deg Fit)')\n",
    "plt.xlabel('Pixel')\n",
    "plt.ylabel('Order')\n",
    "poly = polyval2d(x,y,coeffs8)/y\n",
    "plt.scatter(x,y,c=((poly-w/y)/poly*c.value),vmin=-30,vmax=30)\n",
    "plt.colorbar(label='Residual of Fit [m/s]')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./Figures/191031_deg8.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Design Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit\n",
    "blob = mkBlob(x, y, 8)\n",
    "M = mkDesignMatrix(x, y, blob)\n",
    "coeffs = fit(w, M, 1. / e ** 2)\n",
    "w_poly = predict(x, y, blob, coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual Plot\n",
    "resid = w - w_poly\n",
    "chi = resid / e\n",
    "plt.scatter(x,y,c=resid/w_poly*c.value,vmin=-30,vmax=30,cmap='RdBu_r')\n",
    "plt.title(\"median residual: {:.2e} m/s\".format(np.median(np.abs(resid)/w_poly*c.value)))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Fitting vs. Interpolation\n",
    "We test both fitting the line centers, orders, and wavelengths to a polynomial and using the line centers to interpolate a wavelength solution across the rest of the CCD.\n",
    "\n",
    "We start with `[poly/interp]_train_and_predict` functions that in take some training data (x, m, data, ...) that will be used to construct a model.  We then use this to make predictions for new x and m values.  This allows us to compare how the prediction does compared to the actual data of the new x and m values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_train_and_predict(newx, newm, x, m, data, weights, deg):\n",
    "    blob = mkBlob(x, m, deg)\n",
    "    M = mkDesignMatrix(x, m, blob)\n",
    "    coeffs = fit(data, M, weights)\n",
    "    return predict(newx, newm, blob, coeffs)\n",
    "\n",
    "def interp_train_and_predict(newx, newm, x, m, data, orders=range(86)):\n",
    "    prediction = np.zeros_like(newx)\n",
    "    for r in orders:\n",
    "        Inew = newm == r\n",
    "        if np.sum(Inew):\n",
    "            I = m == r\n",
    "            prediction[Inew] = np.interp(newx[Inew], x[I], data[I],\n",
    "                                         left=np.nan,right=np.nan)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interp even lines from odd lines and vice versa\n",
    "even = np.arange(len(x)) % 2\n",
    "IA = even.astype(bool)\n",
    "IB = (1 - even).astype(bool)\n",
    "\n",
    "w_interp = np.zeros_like(w)\n",
    "w_interp[IA] = interp_train_and_predict(x[IA], y[IA], x[IB], y[IB], w[IB])\n",
    "w_interp[IB] = interp_train_and_predict(x[IB], y[IB], x[IA], y[IA], w[IA])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resid = w - w_stupid\n",
    "chi = resid / e\n",
    "plt.figure()\n",
    "plt.title(\"median residual: {:.2e} m/s\".format(np.nanmedian(np.abs(resid)/w*c.value)))\n",
    "plt.xlabel('Pixel')\n",
    "plt.ylabel('Order')\n",
    "plt.scatter(x,y,c=resid/w*c.value,vmin=-30,vmax=30,cmap='RdBu_r')\n",
    "plt.colorbar(label='Residual [m/s]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure that was so concerning in the polynomial residual plots has disappeared!  We will proceed using the interpolation method for finding new wavelength solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LFC Changes with Exposure\n",
    "We want to characterize how much the LFC changes from exposure to exposure with the ultimate goal of being able to predict how one LFC will look by using another (though more realistically we mean some \"fiducial\" LFC).  To do this, we first characterize how well one LFC exposure can straight up predict another one.  The hope is this will lead to a low-dimensional variation that can be fit using PCA.\n",
    "\n",
    "For our first experiment, we try and predict exposures that are separated by:\n",
    "1. a night\n",
    "1. a month\n",
    "1. a significant shift in the instrument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we select four exposures separated by Different times\n",
    "x1,m1,e1,w1 = readParams('./Checkpoints/LFC_190923.1071.npy')\n",
    "x2,m2,e2,w2 = readParams('./Checkpoints/LFC_190923.1151.npy')\n",
    "x3,m3,e3,w3 = readParams('./Checkpoints/LFC_190905.1062.npy')\n",
    "x4,m4,e4,w4 = readParams('./Checkpoints/LFC_191031.1062.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction over a night\n",
    "w_interp2 = stupid_train_and_predict(x2,m2,x1,m1,w1)\n",
    "\n",
    "resid2 = w2 - w_interp2\n",
    "chi = resid2 / e2\n",
    "plt.figure()\n",
    "plt.scatter(x2,m2,c=resid2/w2*c.value,vmin=-50,vmax=50,cmap='RdBu_r')\n",
    "plt.title('BON -> EON')\n",
    "plt.xlabel('Pixel')\n",
    "plt.ylabel('Order')\n",
    "plt.colorbar(label='Residuals [m/s]')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./Figures/1911101_bon_eon.png')\n",
    "\n",
    "w_poly = poly_train_and_predict(x2,m2,x1,m1,w1,1/e1**2,8)\n",
    "\n",
    "resid2p = w2 - w_poly\n",
    "chi = resid2p / e2\n",
    "plt.figure()\n",
    "plt.scatter(x2,m2,c=resid2p/w2*c.value,vmin=-50,vmax=50,cmap='RdBu_r')\n",
    "plt.title('BON -> EON: Poly')\n",
    "plt.xlabel('Pixel')\n",
    "plt.ylabel('Order')\n",
    "plt.colorbar(label='Residuals [m/s]')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./Figures/1911101_bon_eon_poly.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction over a month\n",
    "w_interp3 = stupid_train_and_predict(x3,m3,x1,m1,w1)\n",
    "\n",
    "resid3 = w3 - w_interp3\n",
    "chi = resid3 / e3\n",
    "plt.figure()\n",
    "plt.scatter(x3,m3,c=resid3/w3*c.value/500,vmin=0,vmax=6,cmap='Reds')\n",
    "plt.title('Sept. 23 -> Sept. 05')\n",
    "plt.xlabel('Pixel')\n",
    "plt.ylabel('Order')\n",
    "plt.colorbar(label='Residuals [pixels]')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./Figures/1911101_190923_190905.png')\n",
    "\n",
    "w_poly3 = poly_train_and_predict(x3,m3,x1,m1,w1,1/e1**3,8)\n",
    "\n",
    "resid3p = w3 - w_poly3\n",
    "chi = resid3p / e3\n",
    "plt.figure()\n",
    "plt.scatter(x3,m3,c=resid3p/w3*c.value/500,vmin=0,vmax=6,cmap='Reds')\n",
    "plt.title('Sept. 23 -> Sept. 05')\n",
    "plt.xlabel('Pixel')\n",
    "plt.ylabel('Order')\n",
    "plt.colorbar(label='Residuals [pixels]')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./Figures/1911101_190923_190905_poly.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction over a significant shift in the instrument\n",
    "w_interp4 = stupid_train_and_predict(x4,m4,x1,m1,w1)\n",
    "\n",
    "resid4 = w4 - w_interp4\n",
    "chi = resid4 / e4\n",
    "plt.figure()\n",
    "plt.scatter(x4,m4,c=resid4/w4*c.value/500,vmin=-6,vmax=0,cmap='Blues_r')\n",
    "plt.title('Sept. 23 -> Oct. 31')\n",
    "plt.xlabel('Pixel')\n",
    "plt.ylabel('Order')\n",
    "plt.colorbar(label='Residuals [pixels]')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./Figures/1911101_190923_191031.png')\n",
    "\n",
    "w_poly4 = stupid_train_and_predict(x4,m4,x1,m1,w1)\n",
    "\n",
    "resid4p = w4 - w_poly4\n",
    "chi = resid4p / e4\n",
    "plt.figure()\n",
    "plt.scatter(x4,m4,c=resid4p/w4*c.value/500,vmin=-6,vmax=0,cmap='Blues_r')\n",
    "plt.title('Sept. 23 -> Oct. 31')\n",
    "plt.xlabel('Pixel')\n",
    "plt.ylabel('Order')\n",
    "plt.colorbar(label='Residuals [pixels]')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./Figures/1911101_190923_191031_poly.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement PCA on Background Variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a window with reasonable lines\n",
    "# (So as to not overwhelm the PCA with noise)\n",
    "plt.plot(x4,m4,'.')\n",
    "ymin,ymax = 40, 75\n",
    "xmin,xmax = 500,7000\n",
    "plt.plot([xmin,xmax,xmax,xmin,xmin],[ymin,ymin,ymax,ymax,ymin],'r-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up area over which t o recover the interpolated wavelength solution\n",
    "x_range=np.arange(xmin,xmax).astype(float)\n",
    "y_range=np.arange(ymin,ymax).astype(float)\n",
    "x_grid, y_grid = np.meshgrid(x_range,y_range)\n",
    "x_grid = x_grid.flatten()\n",
    "y_grid = y_grid.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get wavelength solution for all LFC files\n",
    "cpt_files = glob('./Checkpoints/LFC_190923*.npy')\n",
    "w_fit_array = np.empty((len(cpt_files),len(x_grid)))\n",
    "for i, file_name in enumerate(cpt_files):\n",
    "    x,m,e,w = readParams(file_name)\n",
    "    w_fit_array[i] = interp_train_and_predict(x_grid,y_grid,x,m,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_fit_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for rows with too many bad points\n",
    "good = np.isfinite(w_fit_array)\n",
    "bad = np.logical_not(good)\n",
    "okay = np.sum(good, axis=0) > 3\n",
    "w_fit_array = w_fit_array[:,okay]\n",
    "x_grid = x_grid[okay]\n",
    "y_grid = y_grid[okay]\n",
    "good = np.isfinite(w_fit_array)\n",
    "bad = np.logical_not(good)\n",
    "print(f\"We're Not Okay: {np.sum(~okay)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(good.shape, bad.shape, x_grid.shape, w_fit_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get mean wavelength\n",
    "mean_w_fit = np.nanmean(w_fit_array,axis=0)\n",
    "# Replace bad points with value from mean wavelength\n",
    "# THIS IS TERRIBLE\n",
    "# (BUT RIGHT NOW IT'S OKAY BECAUSE WE'RE GETTING RID OF ALL BAD POINTS)\n",
    "foo = np.zeros_like(w_fit_array) + mean_w_fit[None, :]\n",
    "w_fit_array[bad] = foo[bad] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=5,n_iter=7,random_state=42)\n",
    "svd.fit(w_fit_array - mean_w_fit[None, :])\n",
    "vv = svd.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_grid, y_grid, c=mean_w_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot principle components\n",
    "k = 0\n",
    "plt.figure()\n",
    "plt.scatter(x_grid, y_grid, c=vv[k])\n",
    "plt.title(\"eigenvector {:d}\".format(k))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1\n",
    "plt.figure()\n",
    "plt.scatter(x_grid, y_grid, c=vv[k])\n",
    "plt.title(\"eigenvector {:d}\".format(k))\n",
    "plt.colorbar()\n",
    "\n",
    "k = 2\n",
    "plt.figure()\n",
    "plt.scatter(x_grid, y_grid, c=vv[k])\n",
    "plt.title(\"eigenvector {:d}\".format(k))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
